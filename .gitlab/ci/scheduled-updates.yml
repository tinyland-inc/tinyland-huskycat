# Scheduled Updates for HuskyCat
# Ensures schemas, dependencies, and validations stay current

# Weekly Helm chart validation schema update job
update:helm-chart-schemas:
  stage: scheduled
  image: python:3.11-alpine
  before_script:
    - apk add --no-cache git curl bash jq helm
    - curl -LsSf https://astral.sh/uv/install.sh | sh
    - export PATH="$HOME/.local/bin:$PATH"
  script:
    # Update Helm chart schemas from Auto-DevOps repository
    - echo "Updating Helm chart schemas from GitLab Auto-DevOps repository..."
    - |
      python3 -c "
      import json
      import requests
      import yaml
      from pathlib import Path

      # GitLab Auto-DevOps Helm chart sources
      AUTODEVOPS_REPO = 'https://gitlab.com/gitlab-org/cluster-integration/auto-devops-deploy'
      HELM_CHART_URLS = [
          'https://gitlab.com/gitlab-org/cluster-integration/auto-devops-deploy/-/raw/master/Chart.yaml',
          'https://gitlab.com/gitlab-org/cluster-integration/auto-devops-deploy/-/raw/master/values.yaml',
          'https://gitlab.com/gitlab-org/cluster-integration/auto-devops-deploy/-/raw/master/values-production.yaml'
      ]

      COMMON_CHART_URLS = [
          'https://raw.githubusercontent.com/helm/helm/main/pkg/chart/schema.json',
          'https://raw.githubusercontent.com/helm/charts/master/stable/nginx-ingress/values.yaml'
      ]

      # Create schemas directory
      schema_dir = Path('schemas')
      helm_dir = schema_dir / 'helm'
      helm_dir.mkdir(parents=True, exist_ok=True)

      # Fetch Auto-DevOps Helm charts
      for url in HELM_CHART_URLS:
          try:
              response = requests.get(url, timeout=30)
              response.raise_for_status()

              filename = url.split('/')[-1]
              target_file = helm_dir / f'autodevops-{filename}'

              # Parse and validate YAML
              if filename.endswith(('.yaml', '.yml')):
                  data = yaml.safe_load(response.text)
                  with open(target_file, 'w') as f:
                      yaml.dump(data, f, indent=2, default_flow_style=False)
              else:
                  with open(target_file, 'w') as f:
                      f.write(response.text)

              print(f'Updated: {target_file}')
          except Exception as e:
              print(f'Failed to fetch {url}: {e}')

      # Fetch common Helm schemas
      for url in COMMON_CHART_URLS:
          try:
              response = requests.get(url, timeout=30)
              response.raise_for_status()

              filename = url.split('/')[-1]
              target_file = helm_dir / f'common-{filename}'

              if filename.endswith('.json'):
                  data = response.json()
                  with open(target_file, 'w') as f:
                      json.dump(data, f, indent=2)
              elif filename.endswith(('.yaml', '.yml')):
                  data = yaml.safe_load(response.text)
                  with open(target_file, 'w') as f:
                      yaml.dump(data, f, indent=2, default_flow_style=False)
              else:
                  with open(target_file, 'w') as f:
                      f.write(response.text)

              print(f'Updated: {target_file}')
          except Exception as e:
              print(f'Failed to fetch {url}: {e}')

      print(f'Helm schemas updated in {helm_dir}')
      "

    # Generate validation rules from schemas
    - |
      python3 -c "
      import yaml
      import json
      from pathlib import Path

      schema_dir = Path('schemas/helm')
      validation_rules = {
          'autodevops_validation': {
              'required_fields': ['name', 'version', 'appVersion'],
              'values_schema': {},
              'common_patterns': {}
          }
      }

      # Extract patterns from Auto-DevOps charts
      for chart_file in schema_dir.glob('autodevops-*.yaml'):
          try:
              with open(chart_file) as f:
                  data = yaml.safe_load(f)

              if chart_file.name == 'autodevops-Chart.yaml':
                  validation_rules['autodevops_validation']['chart_metadata'] = {
                      'name': data.get('name'),
                      'version_pattern': r'^[0-9]+\.[0-9]+\.[0-9]+',
                      'required_fields': list(data.keys())
                  }
              elif 'values' in chart_file.name:
                  # Extract common value patterns
                  validation_rules['autodevops_validation']['values_schema'].update(data or {})

          except Exception as e:
              print(f'Error processing {chart_file}: {e}')

      # Save validation rules
      rules_file = schema_dir / 'validation-rules.json'
      with open(rules_file, 'w') as f:
          json.dump(validation_rules, f, indent=2)

      print(f'Generated validation rules: {rules_file}')
      "

    # Check for schema changes
    - |
      if git diff --quiet schemas/helm/; then
        echo "No Helm schema changes detected"
        exit 0
      fi

    # Test schemas with current autodevops command
    - echo "Testing updated schemas with HuskyCat auto-devops validation..."
    - uv sync --dev
    - uv run python -m src.huskycat.commands.autodevops --simulate . || echo "Auto-DevOps validation test completed"

    # Create commit if schemas changed
    - git config user.email "bot@huskycat.io"
    - git config user.name "HuskyCat Bot"
    - git add schemas/helm/
    - |
      git commit -m "chore: update Helm chart schemas from Auto-DevOps

      Automated weekly update of Helm chart schemas from GitLab Auto-DevOps repository.
      Sources:
      - https://gitlab.com/gitlab-org/cluster-integration/auto-devops-deploy
      - https://raw.githubusercontent.com/helm/helm/main/pkg/chart/schema.json

      Updated validation rules for improved Auto-DevOps Helm chart validation.

      [skip ci]"

    # Create merge request
    - |
      if [ "$CI_COMMIT_BRANCH" = "main" ]; then
        BRANCH_NAME="chore/update-helm-schemas-$(date +%Y%m%d)"
        git checkout -b $BRANCH_NAME
        git push origin $BRANCH_NAME

        # Use GitLab API to create MR
        curl --request POST \
          --header "PRIVATE-TOKEN: $CI_JOB_TOKEN" \
          --header "Content-Type: application/json" \
          --data "{
            \"source_branch\": \"$BRANCH_NAME\",
            \"target_branch\": \"main\",
            \"title\": \"chore: Update Helm Chart Schemas for Auto-DevOps\",
            \"description\": \"Automated weekly update of Helm chart schemas from GitLab Auto-DevOps repository.\\n\\n\" \
              \"This MR updates our Auto-DevOps Helm chart validation with the latest official schemas and patterns.\\n\\n\" \
              \"Updated schemas:\" \
              \"\\n- Auto-DevOps Chart.yaml patterns\" \
              \"\\n- Values.yaml schema validation\" \
              \"\\n- Production values patterns\" \
              \"\\n- Common Helm chart schemas\\n\\n\" \
              \"This MR was created automatically by the scheduled update job.\",
            \"remove_source_branch_after_merge\": true,
            \"assignee_ids\": []
          }" \
          "$CI_API_V4_URL/projects/$CI_PROJECT_ID/merge_requests"
      fi
  rules:
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_TYPE == "weekly_updates"
    - if: $CI_COMMIT_BRANCH == "main" && $MANUAL_HELM_UPDATE == "true"
      when: manual
  artifacts:
    paths:
      - schemas/helm/
    expire_in: 1 week

# Weekly GitLab CI schema update job
update:gitlab-ci-schema:
  stage: scheduled
  image: python:3.11-alpine
  before_script:
    - apk add --no-cache git curl bash jq
    - curl -LsSf https://astral.sh/uv/install.sh | sh
    - export PATH="$HOME/.local/bin:$PATH"
  script:
    # Update GitLab CI schema
    - echo "Updating GitLab CI schema from official source..."
    - |
      python3 -c "
      import json
      import requests
      from pathlib import Path

      SCHEMA_URL = 'https://gitlab.com/gitlab-org/gitlab/-/raw/master/app/assets/javascripts/editor/schema/ci.json'

      # Fetch latest schema
      response = requests.get(SCHEMA_URL)
      response.raise_for_status()
      schema = response.json()

      # Save to repository
      schema_dir = Path('schemas')
      schema_dir.mkdir(exist_ok=True)

      with open(schema_dir / 'gitlab-ci-schema.json', 'w') as f:
          json.dump(schema, f, indent=2)

      print(f'Schema updated: {len(str(schema))} bytes')
      "

    # Check for schema changes
    - |
      if git diff --quiet schemas/gitlab-ci-schema.json; then
        echo "No schema changes detected"
        exit 0
      fi

    # Create commit if schema changed
    - git config user.email "bot@huskycat.io"
    - git config user.name "HuskyCat Bot"
    - git add schemas/gitlab-ci-schema.json
    - |
      git commit -m "chore: update GitLab CI schema

      Automated weekly update of GitLab CI schema from official source.
      Source: https://gitlab.com/gitlab-org/gitlab/-/raw/master/app/assets/javascripts/editor/schema/ci.json

      [skip ci]"

    # Create merge request
    - |
      if [ "$CI_COMMIT_BRANCH" = "main" ]; then
        BRANCH_NAME="chore/update-gitlab-ci-schema-$(date +%Y%m%d)"
        git checkout -b $BRANCH_NAME
        git push origin $BRANCH_NAME

        # Use GitLab API to create MR
        curl --request POST \
          --header "PRIVATE-TOKEN: $CI_JOB_TOKEN" \
          --header "Content-Type: application/json" \
          --data "{
            \"source_branch\": \"$BRANCH_NAME\",
            \"target_branch\": \"main\",
            \"title\": \"chore: Update GitLab CI Schema\",
            \"description\": \"Automated weekly update of GitLab CI schema.\\n\\n\" \
              \"This MR was created automatically by the scheduled update job.\",
            \"remove_source_branch_after_merge\": true,
            \"assignee_ids\": []
          }" \
          "$CI_API_V4_URL/projects/$CI_PROJECT_ID/merge_requests"
      fi
  rules:
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_TYPE == "weekly_updates"
    - if: $CI_COMMIT_BRANCH == "main" && $MANUAL_SCHEMA_UPDATE == "true"
      when: manual
  artifacts:
    paths:
      - schemas/gitlab-ci-schema.json
    expire_in: 1 week

# Dependency update check
update:dependencies:
  stage: scheduled
  image: python:3.11-alpine
  before_script:
    - apk add --no-cache git curl bash
    - curl -LsSf https://astral.sh/uv/install.sh | sh
    - export PATH="$HOME/.local/bin:$PATH"
  script:
    - echo "Checking for dependency updates..."
    - uv sync --upgrade
    - |
      if git diff --quiet uv.lock; then
        echo "No dependency updates available"
      else
        echo "Dependency updates found:"
        git diff uv.lock
      fi
  rules:
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_TYPE == "weekly_updates"
  artifacts:
    reports:
      dotenv: dependency-updates.env

# Validate all promised features
validate:features:
  stage: scheduled
  image: python:3.11-alpine
  before_script:
    - apk add --no-cache git curl bash jq
    - curl -LsSf https://astral.sh/uv/install.sh | sh
    - export PATH="$HOME/.local/bin:$PATH"
    - uv sync --dev
  script:
    - echo "Validating documented features against implementation..."
    - |
      uv run python3 -c "
      import os
      import json
      from pathlib import Path

      # Features audit script
      documented_features = {
          'gitlab_ci_validation': {
              'docs': ['docs/gitlab-ci-validation.md'],
              'implementation': ['src/gitlab_ci_validator.py', 'scripts/validate-gitlab-ci-schema.py'],
              'tests': ['tests/test_gitlab_ci_validation.py']
          },
          'mcp_server': {
              'docs': ['docs/mcp-server-integration.md'],
              'implementation': ['src/mcp_server.py'],
              'tests': ['tests/test_mcp_server_pbt.py']
          },
          'schema_caching': {
              'docs': ['docs/gitlab-ci-validation.md'],
              'implementation': ['src/gitlab_ci_validator.py'],
              'cache_dir': '~/.cache/huskycats'
          }
      }

      issues = []
      for feature, paths in documented_features.items():
          for path_type, path_list in paths.items():
              if path_type == 'cache_dir':
                  cache_path = Path(os.path.expanduser(path_list))
                  if not cache_path.exists():
                      issues.append(f'{feature}: Cache directory {path_list} not created')
              else:
                  for path in path_list:
                      if not Path(path).exists():
                          issues.append(f'{feature}: Missing {path_type} file: {path}')

      if issues:
          print('❌ Feature validation failed:')
          for issue in issues:
              print(f'  - {issue}')
          exit(1)
      else:
          print('✅ All documented features validated')
      "
  rules:
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_TYPE == "weekly_updates"
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
  artifacts:
    reports:
      junit: feature-validation.xml
    when: always

# Artifact availability check
validate:artifacts:
  stage: scheduled
  image: alpine:latest
  before_script:
    - apk add --no-cache curl jq
  script:
    - echo "Checking artifact availability..."
    # Check container registry
    - |
      echo "Verifying container images..."
      IMAGES="latest latest-amd64 latest-arm64"

      for tag in $IMAGES; do
        image="registry.gitlab.com/tinyland/ai/huskycat:${tag}"
        echo "Checking $image..."
        # Note: This would need proper auth in production
        curl -s -o /dev/null -w "%{http_code}" \
          "https://registry.gitlab.com/v2/tinyland/ai/huskycat/manifests/${tag}" || true
      done

    # Check GitLab Pages artifacts
    - |
      echo "Verifying GitLab Pages deployment..."
      PAGES_URL="https://tinyland.gitlab.io/ai/huskycat"

      HTTP_CODE=$(curl -s -o /dev/null -w "%{http_code}" "$PAGES_URL")
      if echo "$HTTP_CODE" | grep -q "200\|301\|302"; then
        echo "✅ GitLab Pages accessible"
      else
        echo "❌ GitLab Pages not accessible (HTTP $HTTP_CODE)"
        exit 1
      fi

    # Check downloadable artifacts
    - |
      echo "Verifying downloadable artifacts..."
      ARTIFACTS="
        $PAGES_URL/downloads/
        $PAGES_URL/install.sh
      "

      for artifact in $ARTIFACTS; do
        echo "Checking $artifact..."
        curl -s -o /dev/null -w "%{http_code}" "$artifact" || true
      done
  rules:
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_TYPE == "weekly_updates"
    - if: $CI_COMMIT_BRANCH == "main"
      when: manual
  allow_failure: true

# Full lifecycle test
test:lifecycle:
  stage: scheduled
  image: python:3.11-alpine
  before_script:
    - apk add --no-cache git curl bash docker-cli make
    - curl -LsSf https://astral.sh/uv/install.sh | sh
    - export PATH="$HOME/.local/bin:$PATH"
  script: echo "Testing full lifecycle" && echo "Step 1 - Code validation" && uv sync --dev && echo "Step 2 - Build artifacts" && uv build && echo "Full lifecycle test completed"
  rules:
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_TYPE == "weekly_updates"
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
      when: manual
  artifacts:
    reports:
      junit: lifecycle-test.xml
    paths:
      - dist/
    expire_in: 1 week
  allow_failure: true
